{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El ejemplo base ha sido tomado de:  \n",
    "http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/  \n",
    "Donde puede ser consultado con las explicaciones correspondientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementando una Red Neuronal desde Cero - Una Introducción\n",
    "\n",
    "En este post implementaremos una red neuronal simple de 3 capas desde cero. No derivaremos todas las matemáticas necesarias, pero intentaré dar una explicación intuitiva de lo que estamos haciendo y señalaré recursos para profundizar en los detalles.\n",
    "\n",
    "En este post asumo que estás familiarizado con conceptos básicos de Cálculo y Aprendizaje Automático, por ejemplo, sabes qué es clasificación y regularización. Idealmente, también conoces un poco sobre cómo funcionan técnicas de optimización como el descenso de gradiente. Pero incluso si no estás familiarizado con lo anterior, este post aún podría resultarte interesante ;)\n",
    "\n",
    "Pero, ¿por qué implementar una Red Neuronal desde cero? Incluso si planeas usar librerías de Redes Neuronales como [PyBrain](http://pybrain.org) en el futuro, implementar una red desde cero al menos una vez es un ejercicio extremadamente valioso. Te ayuda a comprender cómo funcionan las redes neuronales, y eso es esencial para diseñar modelos efectivos.\n",
    "\n",
    "Una cosa a tener en cuenta es que los ejemplos de código aquí no son terriblemente eficientes. Están pensados para ser fáciles de entender. En un próximo post exploraré cómo escribir una implementación eficiente de una Red Neuronal usando [Theano](http://deeplearning.net/software/theano/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de paquetes\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "import matplotlib\n",
    "import seaborn as sns  # Añadido para graficar la matriz de confusión\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
    "\n",
    "# Mostrar gráficos en línea y cambiar el tamaño de figura predeterminado\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 8.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generando un conjunto de datos\n",
    "\n",
    "Comencemos generando un conjunto de datos con el que podamos trabajar. Afortunadamente, [scikit-learn](http://scikit-learn.org/) tiene algunos generadores de conjuntos de datos útiles, por lo que no necesitamos escribir el código nosotros mismos. Utilizaremos la función [`make_moons`](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Semilla para reproducibilidad\n",
    "np.random.seed(0)\n",
    "\n",
    "# Generar las dos nubes de puntos con make_blobs\n",
    "X, y = make_blobs(n_samples=1000, centers=[[3, 3], [6, 6]], cluster_std=0.8, random_state=0)\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# Graficar los datos de entrenamiento\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], s=40, c=y_train, cmap=plt.cm.Spectral)\n",
    "plt.title('Datos de Entrenamiento')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos que generamos tiene dos clases, representadas como puntos rojos y azules. Puedes pensar en los puntos azules como pacientes masculinos y los puntos rojos como pacientes femeninos, con los ejes x e y siendo medidas médicas.\n",
    "\n",
    "Nuestro objetivo es entrenar un clasificador de Aprendizaje Automático que prediga la clase correcta (masculino o femenino) dadas las coordenadas x e y. Ten en cuenta que los datos no son *linealmente separables*, no podemos dibujar una línea recta que separe las dos clases. Esto significa que los clasificadores lineales, como la Regresión Logística, no podrán ajustar los datos a menos que ingenies características no lineales (como polinomios) que funcionen bien para el conjunto de datos dado.\n",
    "\n",
    "De hecho, esa es una de las principales ventajas de las Redes Neuronales. No necesitas preocuparte por la [ingeniería de características](http://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/). La capa oculta de una red neuronal aprenderá características por ti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función auxiliar para graficar una frontera de decisión\n",
    "def plot_decision_boundary(pred_func, X, y):\n",
    "    # Establecer valores mínimos y máximos y darle algo de relleno\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    h = 0.01\n",
    "    # Generar una cuadrícula de puntos con distancia h entre ellos\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    # Predecir el valor de la función para toda la cuadrícula\n",
    "    Z = pred_func(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    # Graficar el contorno y los ejemplos\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenando una Red Neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora construiremos una red neuronal de 3 capas con una capa de entrada, una capa oculta y una capa de salida. El número de nodos en la capa de entrada está determinado por la dimensionalidad de nuestros datos, 2. De manera similar, el número de nodos en la capa de salida está determinado por el número de clases que tenemos, también 2. (Debido a que solo tenemos 2 clases, podríamos arreglárnoslas con solo un nodo de salida prediciendo 0 o 1, pero tener 2 hace que sea más fácil extender la red a más clases más adelante). La entrada a la red serán las coordenadas x e y y su salida serán dos probabilidades, una para la clase 0 (\"femenino\") y otra para la clase 1 (\"masculino\"). Se ve algo así:\n",
    "\n",
    "<img src='./nn-3-layer-network.png' style='width: 50%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos elegir la dimensionalidad (el número de nodos) de la capa oculta. Cuantos más nodos pongamos en la capa oculta, más funciones complejas podremos ajustar. Pero una mayor dimensionalidad tiene un costo. Primero, se requiere más computación para hacer predicciones y aprender los parámetros de la red. Un mayor número de parámetros también significa que somos más propensos a sobreajustar nuestros datos.\n",
    "\n",
    "¿Cómo elegir el tamaño de la capa oculta? Aunque hay algunas pautas y recomendaciones generales, siempre depende de tu problema específico y es más un arte que una ciencia. Jugaremos con el número de nodos en la capa oculta más adelante y veremos cómo afecta nuestro resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También necesitamos elegir una *función de activación* para nuestra capa oculta. La función de activación transforma las entradas de la capa en sus salidas. Una función de activación no lineal es lo que nos permite ajustar hipótesis no lineales. Las opciones comunes para las funciones de activación son [tanh](https://reference.wolfram.com/language/ref/Tanh.html), la [función sigmoide](https://es.wikipedia.org/wiki/Funci%C3%B3n_sigmoide) o [ReLUs](https://es.wikipedia.org/wiki/Unidad_lineal_rectificada). Usaremos `tanh`, que funciona bastante bien en muchos escenarios. Una propiedad interesante de estas funciones es que su derivada se puede calcular usando el valor de la función original. Por ejemplo, la derivada de $\\tanh x$ es $1-\\tanh^2 x$. Esto es útil porque nos permite calcular $\\tanh x$ una vez y reutilizar su valor más adelante para obtener la derivada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porque queremos que nuestra red produzca probabilidades, la función de activación para la capa de salida será la [softmax](https://es.wikipedia.org/wiki/Funci%C3%B3n_softmax), que es simplemente una forma de convertir puntuaciones en bruto a probabilidades. Si estás familiarizado con la función logística, puedes pensar en softmax como su generalización a múltiples clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cómo nuestra red hace predicciones\n",
    "\n",
    "Nuestra red hace predicciones usando *propagación hacia adelante*, que es solo un montón de multiplicaciones de matrices y la aplicación de las funciones de activación que definimos anteriormente. Si $x$ es la entrada de 2 dimensiones a nuestra red, entonces calculamos nuestra predicción $\\hat{y}$ (también de dos dimensiones) de la siguiente manera:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "z_1 & = xW_1 + b_1 \\\\\n",
    "a_1 & = \\tanh(z_1) \\\\\n",
    "z_2 & = a_1W_2 + b_2 \\\\\n",
    "a_2 & = \\hat{y} = \\mathrm{softmax}(z_2)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$z_i$ es la entrada de la capa $i$ y $a_i$ es la salida de la capa $i$ después de aplicar la función de activación. $W_1, b_1, W_2, b_2$ son los parámetros de nuestra red, que necesitamos aprender de nuestros datos de entrenamiento. Puedes pensar en ellos como matrices que transforman datos entre las capas de la red. Mirando las multiplicaciones de matrices anteriores, podemos determinar la dimensionalidad de estas matrices. Si usamos 500 nodos para nuestra capa oculta, entonces $W_1 \\in \\mathbb{R}^{2\\times500}$, $b_1 \\in \\mathbb{R}^{500}$, $W_2 \\in \\mathbb{R}^{500\\times2}$, $b_2 \\in \\mathbb{R}^{2}$. Ahora ves por qué tenemos más parámetros si incrementamos el tamaño de la capa oculta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aprendiendo los Parámetros\n",
    "\n",
    "Aprender los parámetros para nuestra red significa encontrar parámetros ($W_1, b_1, W_2, b_2$) que minimicen el error en nuestros datos de entrenamiento. Pero, ¿cómo definimos el error? Llamamos a la función que mide nuestro error la *función de pérdida*. Una elección común con la salida softmax es la [pérdida de entropía cruzada](https://es.wikipedia.org/wiki/Entrop%C3%ADa_cruzada#Funci%C3%B3n_de_error_de_entrop%C3%ADa_cruzada_y_regresi%C3%B3n_log%C3%ADstica). Si tenemos $N$ ejemplos de entrenamiento y $C$ clases, entonces la pérdida para nuestra predicción $\\hat{y}$ con respecto a las etiquetas verdaderas $y$ está dada por:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L(y,\\hat{y}) = - \\frac{1}{N} \\sum_{n \\in N} \\sum_{i \\in C} y_{n,i} \\log\\hat{y}_{n,i}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fórmula parece complicada, pero todo lo que realmente hace es sumar sobre nuestros ejemplos de entrenamiento y añadir a la pérdida si predecimos la clase incorrecta. Entonces, cuanto más alejados estén $y$ (las etiquetas correctas) y $\\hat{y}$ (nuestras predicciones), mayor será nuestra pérdida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuerda que nuestro objetivo es encontrar los parámetros que minimicen nuestra función de pérdida. Podemos usar [descenso de gradiente](http://cs231n.github.io/optimization-1/) para encontrar su mínimo. Implementaré la versión más simple de descenso de gradiente, también llamada descenso de gradiente por lotes con una tasa de aprendizaje fija. Variaciones como SGD (descenso de gradiente estocástico) o descenso de gradiente por minibatch generalmente funcionan mejor en la práctica. Así que si eres serio, querrás usar uno de estos, e idealmente también [reducir la tasa de aprendizaje con el tiempo](http://cs231n.github.io/neural-networks-3/#anneal).\n",
    "\n",
    "Como entrada, el descenso de gradiente necesita los gradientes (vector de derivadas) de la función de pérdida con respecto a nuestros parámetros: $\\frac{\\partial{L}}{\\partial{W_1}}$, $\\frac{\\partial{L}}{\\partial{b_1}}$, $\\frac{\\partial{L}}{\\partial{W_2}}$, $\\frac{\\partial{L}}{\\partial{b_2}}$. Para calcular estos gradientes usamos el famoso *algoritmo de retropropagación*, que es una forma de calcular eficientemente los gradientes empezando desde la salida. No entraré en detalles sobre cómo funciona la retropropagación, pero hay muchas explicaciones excelentes ([aquí](http://colah.github.io/posts/2015-08-Backprop/) o [aquí](http://cs231n.github.io/optimization-2/)) flotando por la web.\n",
    "\n",
    "Aplicando la fórmula de retropropagación encontramos lo siguiente (confía en mí en esto):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "& \\delta_3 = \\hat{y} - y \\\\\n",
    "& \\delta_2 = (1 - \\tanh^2z_1) \\circ \\delta_3W_2^T \\\\\n",
    "& \\frac{\\partial{L}}{\\partial{W_2}} = a_1^T \\delta_3  \\\\\n",
    "& \\frac{\\partial{L}}{\\partial{b_2}} = \\delta_3\\\\\n",
    "& \\frac{\\partial{L}}{\\partial{W_1}} = x^T \\delta_2\\\\\n",
    "& \\frac{\\partial{L}}{\\partial{b_1}} = \\delta_2 \\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación\n",
    "\n",
    "Ahora estamos listos para nuestra implementación. Comenzamos definiendo algunas variables y parámetros útiles para el descenso de gradiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros de la red y del descenso de gradiente\n",
    "nn_input_dim = X_train.shape[1]  # Dimensionalidad de la capa de entrada\n",
    "nn_output_dim = 2  # Dimensionalidad de la capa de salida\n",
    "\n",
    "# Parámetros de descenso de gradiente\n",
    "epsilon = 0.01  # Tasa de aprendizaje para el descenso de gradiente\n",
    "reg_lambda = 0.01  # Fuerza de regularización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero implementemos la función de pérdida que definimos anteriormente. Usamos esto para evaluar qué tan bien está funcionando nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función auxiliar para evaluar la pérdida total en el conjunto de datos\n",
    "def calculate_loss(model, X, y):\n",
    "    num_examples = len(X)\n",
    "    W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2']\n",
    "    # Propagación hacia adelante para calcular nuestras predicciones\n",
    "    z1 = X.dot(W1) + b1\n",
    "    a1 = np.tanh(z1)\n",
    "    z2 = a1.dot(W2) + b2\n",
    "    exp_scores = np.exp(z2)\n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "    # Calculando la pérdida\n",
    "    correct_logprobs = -np.log(probs[range(num_examples), y])\n",
    "    data_loss = np.sum(correct_logprobs)\n",
    "    # Agregar término de regularización a la pérdida (opcional)\n",
    "    data_loss += reg_lambda/2 * (np.sum(np.square(W1)) + np.sum(np.square(W2)))\n",
    "    return 1./num_examples * data_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También implementamos una función auxiliar para calcular la salida de la red. Realiza la propagación hacia adelante como se definió anteriormente y devuelve la clase con la mayor probabilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función auxiliar para predecir probabilidades\n",
    "def predict_probs(model, x):\n",
    "    W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2']\n",
    "    # Propagación hacia adelante\n",
    "    z1 = x.dot(W1) + b1\n",
    "    a1 = np.tanh(z1)\n",
    "    z2 = a1.dot(W2) + b2\n",
    "    exp_scores = np.exp(z2)\n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "    return probs\n",
    "\n",
    "# Función auxiliar para predecir una salida (0 o 1)\n",
    "def predict(model, x):\n",
    "    probs = predict_probs(model, x)\n",
    "    return np.argmax(probs, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También implementamos funciones auxiliares para graficar la curva ROC y la matriz de confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para graficar la curva ROC\n",
    "def plot_roc_curve(fpr, tpr, roc_auc, dataset_type):\n",
    "    plt.plot(fpr, tpr, label='Curva ROC (área = %0.2f)' % roc_auc)\n",
    "    plt.plot([0,1], [0,1], 'k--')\n",
    "    plt.xlim([-0.05,1.0])\n",
    "    plt.ylim([0.0,1.05])\n",
    "    plt.xlabel('Tasa de Falsos Positivos')\n",
    "    plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "    plt.title('Curva ROC (' + dataset_type + ')')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Función para graficar la matriz de confusión\n",
    "def plot_confusion_matrix(cm, dataset_type):\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Matriz de Confusión (' + dataset_type + ')')\n",
    "    plt.ylabel('Etiqueta Real')\n",
    "    plt.xlabel('Etiqueta Predicha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, aquí viene la función para entrenar nuestra Red Neuronal. Implementa descenso de gradiente por lotes usando las derivadas de retropropagación que encontramos anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función del modelo de Red Neuronal\n",
    "def build_model(X, y, nn_hdim, num_passes=20000, print_loss=False):\n",
    "    num_examples = len(X)\n",
    "    nn_input_dim = X.shape[1]\n",
    "    nn_output_dim = 2  # Número de clases\n",
    "\n",
    "    # Parámetros de descenso de gradiente\n",
    "    epsilon = 0.01  # Tasa de aprendizaje\n",
    "    reg_lambda = 0.01  # Fuerza de regularización\n",
    "\n",
    "    # Inicializar los parámetros a valores aleatorios\n",
    "    np.random.seed(0)\n",
    "    W1 = np.random.randn(nn_input_dim, nn_hdim) / np.sqrt(nn_input_dim)\n",
    "    b1 = np.zeros((1, nn_hdim))\n",
    "    W2 = np.random.randn(nn_hdim, nn_output_dim) / np.sqrt(nn_hdim)\n",
    "    b2 = np.zeros((1, nn_output_dim))\n",
    "\n",
    "    # Esto es lo que devolvemos al final\n",
    "    model = {}\n",
    "\n",
    "    # Descenso de gradiente\n",
    "    for i in range(0, num_passes):\n",
    "\n",
    "        # Propagación hacia adelante\n",
    "        z1 = X.dot(W1) + b1\n",
    "        a1 = np.tanh(z1)\n",
    "        z2 = a1.dot(W2) + b2\n",
    "        exp_scores = np.exp(z2)\n",
    "        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\n",
    "        # Retropropagación\n",
    "        delta3 = probs\n",
    "        delta3[range(num_examples), y] -= 1\n",
    "        dW2 = (a1.T).dot(delta3)\n",
    "        db2 = np.sum(delta3, axis=0, keepdims=True)\n",
    "        delta2 = delta3.dot(W2.T) * (1 - np.power(a1, 2))\n",
    "        dW1 = np.dot(X.T, delta2)\n",
    "        db1 = np.sum(delta2, axis=0)\n",
    "\n",
    "        # Agregar términos de regularización\n",
    "        dW2 += reg_lambda * W2\n",
    "        dW1 += reg_lambda * W1\n",
    "\n",
    "        # Actualización de parámetros por descenso de gradiente\n",
    "        W1 += -epsilon * dW1\n",
    "        b1 += -epsilon * db1\n",
    "        W2 += -epsilon * dW2\n",
    "        b2 += -epsilon * db2\n",
    "\n",
    "        # Asignar nuevos parámetros al modelo\n",
    "        model = {'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}\n",
    "\n",
    "        # Opcionalmente imprimir la pérdida\n",
    "        if print_loss and i % 1000 == 0:\n",
    "            loss = calculate_loss(model, X, y)\n",
    "            print(f\"Pérdida después de la iteración {i}: {loss}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variando el tamaño de la capa oculta\n",
    "\n",
    "En el ejemplo anterior, elegimos un tamaño de capa oculta de 3. Ahora obtengamos una idea de cómo variar el tamaño de la capa oculta afecta el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hidden_layer_dimensions = [1, 3, 5, 20, 50]\n",
    "\n",
    "for nn_hdim in hidden_layer_dimensions:\n",
    "    print('Tamaño de la Capa Oculta %d' % nn_hdim)\n",
    "    # Entrenar el modelo\n",
    "    model = build_model(X_train, y_train, nn_hdim)\n",
    "\n",
    "    # Calcular probabilidades en los conjuntos de entrenamiento y prueba\n",
    "    probs_train = predict_probs(model, X_train)\n",
    "    probs_test = predict_probs(model, X_test)\n",
    "\n",
    "    # Calcular clases predichas\n",
    "    y_pred_train = np.argmax(probs_train, axis=1)\n",
    "    y_pred_test = np.argmax(probs_test, axis=1)\n",
    "\n",
    "    # Calcular curvas ROC y AUC\n",
    "    fpr_train, tpr_train, _ = roc_curve(y_train, probs_train[:, 1])\n",
    "    roc_auc_train = auc(fpr_train, tpr_train)\n",
    "\n",
    "    fpr_test, tpr_test, _ = roc_curve(y_test, probs_test[:, 1])\n",
    "    roc_auc_test = auc(fpr_test, tpr_test)\n",
    "\n",
    "    # Calcular matrices de confusión\n",
    "    cm_train = confusion_matrix(y_train, y_pred_train)\n",
    "    cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "    # Graficar\n",
    "    # Crear una figura con 3 filas y 2 columnas\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(12, 18))\n",
    "    fig.suptitle('Tamaño de la Capa Oculta %d' % nn_hdim, fontsize=16)\n",
    "\n",
    "    # Primera fila: Fronteras de decisión\n",
    "    plt.sca(axes[0, 0])\n",
    "    plot_decision_boundary(lambda x: predict(model, x), X_train, y_train)\n",
    "    plt.title('Frontera de Decisión (Entrenamiento)')\n",
    "\n",
    "    plt.sca(axes[0, 1])\n",
    "    plot_decision_boundary(lambda x: predict(model, x), X_test, y_test)\n",
    "    plt.title('Frontera de Decisión (Prueba)')\n",
    "\n",
    "    # Segunda fila: Curvas ROC\n",
    "    plt.sca(axes[1, 0])\n",
    "    plot_roc_curve(fpr_train, tpr_train, roc_auc_train, 'Entrenamiento')\n",
    "\n",
    "    plt.sca(axes[1, 1])\n",
    "    plot_roc_curve(fpr_test, tpr_test, roc_auc_test, 'Prueba')\n",
    "\n",
    "    # Tercera fila: Matrices de confusión\n",
    "    plt.sca(axes[2, 0])\n",
    "    plot_confusion_matrix(cm_train, 'Entrenamiento')\n",
    "\n",
    "    plt.sca(axes[2, 1])\n",
    "    plot_confusion_matrix(cm_test, 'Prueba')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.92)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que mientras una capa oculta de baja dimensionalidad captura bien la tendencia general de nuestros datos, las dimensionalidades más altas son propensas al sobreajuste. Están \"memorizando\" los datos en lugar de ajustar la forma general. Si evaluáramos nuestro modelo en un conjunto de prueba separado (¡y deberías!), el modelo con un tamaño de capa oculta más pequeño probablemente rendiría mejor porque generaliza mejor. Podríamos contrarrestar el sobreajuste con una regularización más fuerte, pero elegir el tamaño correcto para la capa oculta es una solución mucho más \"económica\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
