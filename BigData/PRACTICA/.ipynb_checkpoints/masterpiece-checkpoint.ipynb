{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install autoviz\n",
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Description\n",
    "\n",
    "## Overview\n",
    "The data has been split into two groups:\n",
    "1. **Training set** (`train.csv`)\n",
    "2. **Test set** (`test.csv`)\n",
    "\n",
    "The **training set** should be used to build your machine learning models. For the training set, we provide the outcome (also known as the *ground truth*) for each passenger. Your model will be based on “features” like passengers’ gender and class. You can also use feature engineering to create new features.\n",
    "\n",
    "The **test set** should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.\n",
    "\n",
    "We also include `gender_submission.csv`, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.\n",
    "\n",
    "---\n",
    "\n",
    "## Data Dictionary\n",
    "\n",
    "| Variable | Definition                                   | Key                                     |\n",
    "|----------|----------------------------------------------|-----------------------------------------|\n",
    "| survival | Survival                                     | 0 = No, 1 = Yes                         |\n",
    "| pclass   | Ticket class                                 | 1 = 1st, 2 = 2nd, 3 = 3rd               |\n",
    "| sex      | Sex                                          |                                         |\n",
    "| age      | Age in years                                 |                                         |\n",
    "| sibsp    | # of siblings/spouses aboard the Titanic     |                                         |\n",
    "| parch    | # of parents/children aboard the Titanic     |                                         |\n",
    "| ticket   | Ticket number                                |                                         |\n",
    "| fare     | Passenger fare                               |                                         |\n",
    "| cabin    | Cabin number                                 |                                         |\n",
    "| embarked | Port of Embarkation                          | C = Cherbourg, Q = Queenstown, S = Southampton |\n",
    "\n",
    "---\n",
    "\n",
    "## Variable Notes\n",
    "\n",
    "- **pclass**: A proxy for socio-economic status (SES)\n",
    "  - 1st = Upper\n",
    "  - 2nd = Middle\n",
    "  - 3rd = Lower\n",
    "\n",
    "- **age**: Age is fractional if less than 1. If the age is estimated, it is in the form of xx.5\n",
    "\n",
    "- **sibsp**: The dataset defines family relations in this way:\n",
    "  - Sibling = brother, sister, stepbrother, stepsister\n",
    "  - Spouse = husband, wife (mistresses and fiancés were ignored)\n",
    "\n",
    "- **parch**: The dataset defines family relations in this way:\n",
    "  - Parent = mother, father\n",
    "  - Child = daughter, son, stepdaughter, stepson\n",
    "\n",
    "  Some children traveled only with a nanny, therefore `parch=0` for them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sinking of the Titanic is one of the most infamous shipwrecks in history.\n",
    "\n",
    "On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n",
    "\n",
    "While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n",
    "\n",
    "In this challenge, we ask you to build a predictive model that answers the question: “what sorts of people were more likely to survive?” using passenger data (ie name, age, gender, socio-economic class, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "pd.set_option('display.max_columns', 500)\n",
    "import joblib # export model\n",
    "from datetime import datetime # cek waktu proses\n",
    "\n",
    "import category_encoders as ce # binary encoding\n",
    "\n",
    "# machine learning\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#automate EDA\n",
    "from autoviz.AutoViz_Class import AutoViz_Class\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laod the data\n",
    "df_train = pd.read_csv('./input/titanic/train.csv')\n",
    "df_test = pd.read_csv('./input/titanic/test.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check tail\n",
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check pclass\n",
    "df_train['Pclass'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check sex\n",
    "df_train['Sex'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check age\n",
    "df_train['Age'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check sibsp\n",
    "df_train['SibSp'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check cabin\n",
    "df_train['Cabin'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check statistical summary\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing value\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing values\n",
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check uniqueness\n",
    "df_train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove cabin,name, ticker, pId\n",
    "df_train = df_train.drop(['Cabin','Name','Ticket','PassengerId'], axis=1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove cabin,name, ticker, pId\n",
    "df_test = df_test.drop(['Cabin','Name','Ticket','PassengerId'], axis=1)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check null train\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check null test\n",
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train summary\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test summary\n",
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual EDA -> age\n",
    "plt.hist(df_train['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual EDA -> SibSp\n",
    "plt.hist(df_train['SibSp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual EDA -> parch\n",
    "plt.hist(df_train['Parch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual EDA -> fare\n",
    "plt.scatter(df_train['Fare'], df_train['Survived'])\n",
    "plt.xlabel(\"Fare\")\n",
    "plt.ylabel(\"Survived\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average imputation on train test\n",
    "df_train['Age'] = df_train['Age'].fillna(df_train['Age'].mean())\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average imputation on test test\n",
    "df_test['Age'] = df_test['Age'].fillna(df_test['Age'].mean())\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and fare\n",
    "df_test['Fare'] = df_test['Fare'].fillna(df_test['Fare'].mean())\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual EDA (Exploratory Data Analysis)-> age\n",
    "plt.hist(df_train['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual EDA -> age\n",
    "plt.hist(df_test['Age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    pd.get_dummies: Función de pandas que transforma una columna categórica en múltiples columnas binarias.\n",
    "\n",
    "    df_test.sex: Especifica la columna del DataFrame de prueba que se desea transformar.\n",
    "\n",
    "    prefix='sex': Agrega el prefijo \"Parch\" al nombre de cada columna dummy generada.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sex -> getdummy on train\n",
    "sex_dummy = pd.get_dummies(df_train.Sex, prefix='sex')\n",
    "df_train = pd.concat([df_train, sex_dummy], axis=1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sex -> getdummy on test\n",
    "sex_dummy = pd.get_dummies(df_test.Sex, prefix='sex')\n",
    "df_test = pd.concat([df_test, sex_dummy], axis=1)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sibsp -> getdummy on train\n",
    "sibsp_dummy = pd.get_dummies(df_train.SibSp, prefix='SibSp')\n",
    "df_train = pd.concat([df_train, sibsp_dummy], axis=1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sibsp -> getdummy on test\n",
    "sibsp_dummy = pd.get_dummies(df_test.SibSp, prefix='SibSp')\n",
    "df_test = pd.concat([df_test, sibsp_dummy], axis=1)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parch -> getdummy on train\n",
    "parch_dummy = pd.get_dummies(df_train.Parch, prefix='Parch')\n",
    "df_train = pd.concat([df_train, parch_dummy], axis=1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parch -> getdummy on test\n",
    "parch_dummy = pd.get_dummies(df_test.Parch, prefix='Parch')\n",
    "df_test = pd.concat([df_test, parch_dummy], axis=1)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embarked -> getdummy on train\n",
    "emb_dummy = pd.get_dummies(df_train.Embarked, prefix='Embarked')\n",
    "df_train = pd.concat([df_train, emb_dummy], axis=1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embarked -> getdummy on test\n",
    "emb_dummy = pd.get_dummies(df_test.Embarked, prefix='Embarked')\n",
    "df_test = pd.concat([df_test, emb_dummy], axis=1)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop redundant data on train\n",
    "df_train.drop(['Sex','SibSp','Parch','Embarked'], axis=1, inplace=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop redundant data on test\n",
    "df_test.drop(['Sex','SibSp','Parch','Embarked'], axis=1, inplace=True)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check train\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check test\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check train\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check column\n",
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_columns = ['Survived', 'Pclass', 'Age', 'Fare', 'sex_female', 'sex_male',\n",
    "       'SibSp_0', 'SibSp_1', 'SibSp_2', 'SibSp_3', 'SibSp_4', 'SibSp_5',\n",
    "       'SibSp_8', 'Parch_0', 'Parch_1', 'Parch_2', 'Parch_3', 'Parch_4',\n",
    "       'Parch_5', 'Parch_6', 'Embarked_C', 'Embarked_Q', 'Embarked_S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_columns = ['Pclass', 'Age', 'Fare', 'sex_female', 'sex_male', 'SibSp_0', 'SibSp_1',\n",
    "       'SibSp_2', 'SibSp_3', 'SibSp_4', 'SibSp_5', 'SibSp_8', 'Parch_0',\n",
    "       'Parch_1', 'Parch_2', 'Parch_3', 'Parch_4', 'Parch_5', 'Parch_6',\n",
    "       'Parch_9', 'Embarked_C', 'Embarked_Q', 'Embarked_S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "# Min Max scaler -> X\n",
    "X_train = df_train\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train)\n",
    "\n",
    "X_train.columns = X_train_columns\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "# Min Max scaler -> X\n",
    "X_test = df_test\n",
    "scaler = MinMaxScaler()\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n",
    "X_test.columns = X_test_columns\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check point <- well done\n",
    "X_train.to_csv('df_pos_train.csv', encoding='utf-8', index=False)\n",
    "X_test.to_csv('df_pos_test.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load truely meaningful data\n",
    "df_pos_train = pd.read_csv('df_pos_train.csv')\n",
    "df_pos_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape\n",
    "df_pos_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check correlation\n",
    "df_pos_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto EDA with autoviz library\n",
    "AV = AutoViz_Class()\n",
    "AV.AutoViz('df_pos_train.csv', depVar='Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize num_feats\n",
    "num_feats = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dependent and independent variables\n",
    "y = df_pos_train['Survived']\n",
    "X = df_pos_train.drop('Survived', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. PEARSON CORRELATION (filter methods)\n",
    "def cor_selector(X, y,num_feats):\n",
    "    cor_list = []\n",
    "    feature_name = X.columns.tolist()\n",
    "    # calculate the correlation with y for each feature\n",
    "    for i in X.columns.tolist():\n",
    "        cor = np.corrcoef(X[i], y)[0, 1]\n",
    "        cor_list.append(cor)\n",
    "    # replace NaN with 0\n",
    "    cor_list = [0 if np.isnan(i) else i for i in cor_list]\n",
    "    # feature name\n",
    "    cor_feature = X.iloc[:,np.argsort(np.abs(cor_list))[-num_feats:]].columns.tolist()\n",
    "    # feature selection? 0 for not select, 1 for select\n",
    "    cor_support = [True if i in cor_feature else False for i in feature_name]\n",
    "    return cor_support, cor_feature\n",
    "cor_support, cor_feature = cor_selector(X, y,num_feats)\n",
    "print(str(len(cor_feature)), 'selected features')\n",
    "\n",
    "print(\"pearson correlation\")\n",
    "print(cor_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. CHI SQUARE FEATURES (filter methods)\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_norm = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "chi_selector = SelectKBest(chi2, k=num_feats)\n",
    "chi_selector.fit(X_norm, y)\n",
    "chi_support = chi_selector.get_support()\n",
    "chi_feature = X.loc[:,chi_support].columns.tolist()\n",
    "print(str(len(chi_feature)), 'selected features')\n",
    "\n",
    "print(\"chi feature\")\n",
    "print(chi_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.RECURSIVE FEATURE ELIMINATION (wrapper methods)\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "rfe_selector = RFE(estimator=LogisticRegression(solver='lbfgs'), n_features_to_select=num_feats, step=10, verbose=5)\n",
    "rfe_selector.fit(X_norm, y)\n",
    "\n",
    "rfe_support = rfe_selector.get_support()\n",
    "rfe_feature = X.loc[:,rfe_support].columns.tolist()\n",
    "print(str(len(rfe_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. LASSO: SELECT FROM MODEL (embedded methods)\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_norm = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "embeded_lr_selector = SelectFromModel(LogisticRegression(penalty='l1', solver='liblinear'), max_features=num_feats)\n",
    "embeded_lr_selector.fit(X_norm, y)\n",
    "\n",
    "embeded_lr_support = embeded_lr_selector.get_support()\n",
    "embeded_lr_feature = X.loc[:,embeded_lr_support].columns.tolist()\n",
    "print(str(len(embeded_lr_feature)), 'selected features')\n",
    "\n",
    "print(\"lasso model\")\n",
    "print(embeded_lr_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. TREE BASED SELECT FROM MODEL\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(n_estimators=10, max_depth=6), max_features=num_feats)\n",
    "embeded_rf_selector.fit(X, y)\n",
    "\n",
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = X.loc[:,embeded_rf_support].columns.tolist()\n",
    "print(str(len(embeded_rf_feature)), 'selected features')\n",
    "\n",
    "\n",
    "print(\"random forest\")\n",
    "print(embeded_rf_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OVERALL\n",
    "pd.set_option('display.max_rows', None)\n",
    "feature_name = X.columns.tolist()\n",
    " #put all selection together\n",
    "feature_selection_df = pd.DataFrame({'Feature':feature_name, 'Pearson':cor_support, 'Chi-2':chi_support, 'RFE':rfe_support, 'LASSO':embeded_lr_support,\n",
    "                                    'Random Forest':embeded_rf_support})\n",
    "# Contar las selecciones solo en las columnas numéricas\n",
    "feature_selection_df['Total'] = feature_selection_df[['Pearson', 'Chi-2', 'RFE', 'LASSO', 'Random Forest']].sum(axis=1)\n",
    "\n",
    "# Mostrar los top 100 (o el número de features deseado)\n",
    "feature_selection_df = feature_selection_df.sort_values(['Total', 'Feature'], ascending=False)\n",
    "feature_selection_df.index = range(1, len(feature_selection_df) + 1)\n",
    "print(feature_selection_df.head(num_feats))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only the selected value\n",
    "X_filtered = X[['sex_female', 'Pclass', 'sex_male', 'SibSp_1', 'Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test dataset\n",
    "# train and test ratio => 80:20\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_filtered, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train shape: ', X_train.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('X_val shape: ', X_val.shape)\n",
    "print('y_val shape: ', y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgbModel = XGBClassifier(learning_rate=0.01, max_depth=4, n_estimators=300, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train xgboost\n",
    "xgbModel.fit(X_train, y_train)\n",
    "\n",
    "y_xgb_pred_train = xgbModel.predict(X_train)\n",
    "y_xgb_pred_val = xgbModel.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate xgboost\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"XGBoost Training accuracy: \", accuracy_score(y_train, y_xgb_pred_train))\n",
    "print(\"XGBoost Validation accuracy: \", accuracy_score(y_val, y_xgb_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest\n",
    "RFModel = RandomForestClassifier(criterion='gini',\n",
    "                                           n_estimators=1750,\n",
    "                                           max_depth=7,\n",
    "                                           min_samples_split=6,\n",
    "                                           min_samples_leaf=6,\n",
    "                                           max_features='sqrt',\n",
    "                                           oob_score=True,\n",
    "                                           random_state=42,\n",
    "                                           n_jobs=-1,\n",
    "                                           verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train random forest\n",
    "RFModel.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_rf_pred_train = RFModel.predict(X_train)\n",
    "y_rf_pred_val = RFModel.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate random forest\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"RF Training accuracy: \", accuracy_score(y_train, y_rf_pred_train))\n",
    "print(\"RF Validation accuracy: \", accuracy_score(y_val, y_rf_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix for the best model (RF in this case)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\"\\nConfusion Matrix for RF model\\n\")\n",
    "cm = confusion_matrix(y_val, y_rf_pred_val)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix visualization\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, ax = ax, fmt='g',cmap='Blues') #annot=True to annotate cells\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ok nice, now we get RF as the best model. Now, we gonna train this model once more with the full train data.\n",
    "RFModel.fit(X_filtered, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this case, Random Forrest has better accuracy than XGBoost with <b>84.26% training score</b> and <b>81% validation score</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get passengerId to fit the submission format\n",
    "passengerId = pd.read_csv('./input/titanic/test.csv')\n",
    "passengerId = passengerId['PassengerId']\n",
    "passengerId.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ready test data\n",
    "df_submit = pd.read_csv('df_pos_test.csv')\n",
    "df_submit = df_submit[['sex_female', 'Pclass', 'sex_male', 'SibSp_1', 'Age']]\n",
    "df_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create prediction\n",
    "preds = RFModel.predict(df_submit.values)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df format\n",
    "df = {'PassengerId': passengerId.ravel(), 'Survived': preds}\n",
    "df_predictions = pd.DataFrame(df)\n",
    "df_predictions.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the float to int format\n",
    "df_predictions['Survived']=df_predictions['Survived'].astype(int)\n",
    "df_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save output, then submit\n",
    "df_predictions.to_csv('final_answer.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 26502,
     "sourceId": 3136,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30035,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
